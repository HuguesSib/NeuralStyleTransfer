{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0433e16a5b76b6e97ae6bc68681413c142e13c9d9746671684923ff9cd34df70b",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "433e16a5b76b6e97ae6bc68681413c142e13c9d9746671684923ff9cd34df70b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Neural Style Transfer \n",
    "## DD2424 Project based on : 'A Neural Algorithm of Artistic Style' Leon A. Gatys,Alexander S. Ecker,Matthias Bethge\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import packages and libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import Model\n",
    "\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import time\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following the method of the paper : we first import the VGG19-Network. The\n",
    "#feature space provided by the 16 convolutional and 5 pooling layers of the 19 #layer VGGNetwork\n",
    "\n",
    "VGG19 = tf.keras.applications.VGG19(include_top=False)\n",
    "\n",
    "content_layers = ['block5_conv2'] \n",
    "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1','block5_conv1']\n",
    "\n",
    "num_content_layers = len(content_layers)\n",
    "num_style_layers = len(style_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Content features Size : \n(1, 14, 14, 512)\nStyle features Size : \n(1, 224, 224, 64)\n(1, 112, 112, 128)\n(1, 56, 56, 256)\n(1, 28, 28, 512)\n(1, 14, 14, 512)\n"
     ]
    }
   ],
   "source": [
    "#Get the path of the pictures we want\n",
    "content_path = tf.keras.utils.get_file('jul.jpg', 'https://img.lemde.fr/2020/11/18/494/0/8688/4340/1440/720/60/0/7d2c869_856070765-jul-fifou-0888.jpg')\n",
    "style_path = tf.keras.utils.get_file('titi.jpg', 'https://i.pinimg.com/originals/99/d3/21/99d321028e0803f9c928aadc78f934f8.jpg')\n",
    "\n",
    "#Load them\n",
    "content_img = loadImg(content_path)\n",
    "style_img = loadImg(style_path)\n",
    "\n",
    "#Get the model\n",
    "content_model = vgg_model(content_layers)\n",
    "style_model = vgg_model(style_layers)\n",
    "\n",
    "#Create the features map of both images\n",
    "content_features = content_model.predict(content_img)\n",
    "style_features = style_model.predict(style_img)\n",
    "\n",
    "#Print shapes to debug\n",
    "print (\"Content features Size : \")\n",
    "print(content_features.shape)\n",
    "print('Style features Size : ')\n",
    "for i in range(len(style_features)):\n",
    "    print(style_features[i].shape)"
   ]
  },
  {
   "source": [
    "## Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load images and preprocess them to the correct shape\n",
    "def loadImg(path): \n",
    "  x = load_img(path, target_size= (224, 224))\n",
    "  x = img_to_array(x)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  return preprocess_input(x)\n",
    "\n",
    "def vgg_model(layers): \n",
    "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    outputs = [vgg.get_layer(name).output for name in layers]\n",
    "    model = tf.keras.Model([vgg.input], outputs)\n",
    "    return model"
   ]
  }
 ]
}